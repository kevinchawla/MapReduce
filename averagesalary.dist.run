#!/bin/bash

#SBATCH -A uot165 
#SBATCH --job-name="Average Salary"
#SBATCH --output="averagesalary.distr.out"
#SBATCH --partition=compute
## allocate 3 nodes for the Hadoop cluster: 3 datanodes, from which 1 is namenode 
#SBATCH --nodes=3
#SBATCH --ntasks-per-node=1
#SBATCH --mem=5G
#SBATCH --export=ALL 
#SBATCH --time=60
export HADOOP_CONF_DIR=/home/$USER/cometcluster
module load hadoop/2.6.0
export JAVA_HOME=/lib/jvm/java
myhadoop-configure.sh
start-dfs.sh
start-yarn.sh

hdfs dfs -mkdir -p /user/$USER
hdfs dfs -put input /user/$USER/input
hadoop jar AverageSalary.jar AverageSalary /user/$USER/input /user/$USER/output-distr
rm -rf output-distr
mkdir output-distr
hdfs dfs -get /user/$USER/output-distr/* output-distr/

stop-yarn.sh
stop-dfs.sh
